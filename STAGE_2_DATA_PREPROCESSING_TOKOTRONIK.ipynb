{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nurpurwanto/EDM-FINPRO-ECOMMERCE-SHIPPING/blob/main/STAGE_2_DATA_PREPROCESSING_TOKOTRONIK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products.**"
      ],
      "metadata": {
        "id": "JE_5wmAweLoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Description**\n",
        "\n",
        "**ID**: ID Number of Customers.\n",
        "\n",
        "**Warehouse block**: The Company have big Warehouse which is divided in to block such as A,B,C,D,E.\n",
        "\n",
        "**Mode of shipment**:The Company Ships the products in multiple way such as Ship, Flight and Road.\n",
        "\n",
        "**Customer care calls**: The number of calls made from enquiry for enquiry of the shipment.\n",
        "\n",
        "**Customer rating**: The company has rated from every customer. 1 is the lowest (Worst), 5 is the highest (Best).\n",
        "\n",
        "**Cost of the product**: Cost of the Product in US Dollars.\n",
        "\n",
        "**Prior purchases**: The Number of Prior Purchase.\n",
        "\n",
        "**Product importance**: The company has categorized the product in the various parameter such as low, medium, high.\n",
        "\n",
        "**Gender**: Male and Female.\n",
        "\n",
        "**Discount offered**: Discount offered on that specific product.\n",
        "\n",
        "**Weight in gms**: It is the weight in grams.\n",
        "\n",
        "**Reached on time**: It is the target variable, where 1 Indicates that the product has NOT reached on time and 0 indicates it has reached on time.\n",
        "\n",
        "\n",
        "[Source Dataset](https://www.kaggle.com/datasets/prachi13/customer-analytics?select=Train.csv)"
      ],
      "metadata": {
        "id": "QA2d0BpceOkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Library"
      ],
      "metadata": {
        "id": "hotF8bu5er4Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5446fd05-9f75-4df6-ad05-b7c5fec653f6"
      },
      "outputs": [],
      "source": [
        "#Lib for dataframe, agg, and data viz\n",
        "from IPython import display\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "rcParams['figure.figsize'] = 12, 4\n",
        "rcParams['lines.linewidth'] = 0\n",
        "rcParams['xtick.labelsize'] = 'x-large'\n",
        "rcParams['ytick.labelsize'] = 'x-large'\n",
        "plt.style.use('fivethirtyeight')\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "import numpy as np\n",
        "from textwrap import wrap\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#lib for preprocessing\n",
        "# Library for Scalling Data\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from scipy.stats import boxcox\n",
        "import warnings\n",
        "# Library for Split Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Library for Z-Score\n",
        "from scipy import stats\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Algorithm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data Frame"
      ],
      "metadata": {
        "id": "faizt0ziexOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx9pNbP-7nv4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD4_K3247rRc"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/My Drive/Colab Notebooks/FINPRO RAKAMIN 29/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Train.csv')\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "pzX8pZbgfWGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df=df.drop(\"ID\", axis='columns')\n",
        "\n",
        "df['Customer_rating']=df['Customer_rating'].astype(np.object)\n",
        "df['Reached.on.Time_Y.N']=df['Reached.on.Time_Y.N'].astype(np.object)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "QxxV-o20upmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG4yXN_bTiva"
      },
      "outputs": [],
      "source": [
        "df_numerical = df.select_dtypes(exclude='object')\n",
        "df_categorical = df.select_dtypes(include='object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9qrYqrsT2TV"
      },
      "outputs": [],
      "source": [
        "numerical = df_numerical.columns.values\n",
        "categorical = df_categorical.columns.values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleansing (50 poin) \n",
        "\n",
        "\n",
        "Lakukan pembersihan data, sesuai yang diajarkan di kelas, seperti:\n",
        "\n",
        "1. Handle missing values\n",
        "\n",
        "2. Handle duplicated data\n",
        "\n",
        "3. Handle outliers\n",
        "\n",
        "4. Feature transformation\n",
        "\n",
        "5. Feature encoding\n",
        "\n",
        "6. Handle class imbalance\n",
        "\n",
        "Di laporan homework, tuliskan apa saja yang telah dilakukan dan metode yang digunakan.\u000b\u000b* Tetap tuliskan jika memang ada tidak yang perlu di-handle (contoh: “Tidak perlu feature encoding karena semua feature sudah numerical” atau “Outlier tidak di-handle karena akan fokus menggunakan model yang robust terhadap outlier”).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D6kFGUzqR2oZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering (35 poin) \n",
        "\n",
        "Cek feature yang ada sekarang, lalu lakukan:\n",
        "\n",
        "A. Feature selection (membuang feature yang kurang relevan atau redundan)\n",
        "\n",
        "B. Feature extraction (membuat feature baru dari feature yang sudah ada)\n",
        "\n",
        "C. Tuliskan minimal 4 feature tambahan (selain yang sudah tersedia di dataset) yang mungkin akan sangat membantu membuat performansi model semakin bagus (ini hanya ide saja, untuk menguji kreativitas teman-teman, tidak perlu benar-benar dicari datanya dan tidak perlu diimplementasikan)\n",
        "\n",
        "* Untuk 2A & 2B, tetap tuliskan jika memang tidak bisa dilakukan (contoh: “Semua feature digunakan untuk modelling (tidak ada yang dihapus), karena semua feature relevan”)\n"
      ],
      "metadata": {
        "id": "ljAkShfnS7j9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgOwIDVEOZfN"
      },
      "source": [
        "# Stage 2 Pre-processing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX7UQD7WOpWH"
      },
      "source": [
        "## Handle Outliers\n",
        "\n",
        "### Z-Score Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch2_Yw5TOeyF"
      },
      "outputs": [],
      "source": [
        "df_outliers = ['Prior_purchases', 'Discount_offered']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5frkoykO21Y"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "for i in df_outliers:\n",
        "    print(i)\n",
        "    z_scores = zscore(df[i])\n",
        "    print(\"*\"*50)\n",
        "    for threshold in np.arange(1,5,0.5):\n",
        "        print(\"Treshold: {}\".format(threshold))\n",
        "        print(\"Amount of Outliers: {}\".format(len((np.where(z_scores >= threshold)[0]))))\n",
        "        print('------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdlDFa07PBsd"
      },
      "source": [
        "### Decision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruKyr_RFPKlr"
      },
      "outputs": [],
      "source": [
        "print(f'Number of rows before deleting outliers: {len(df)}')\n",
        "\n",
        "filtered_entries = np.array([True] * len(df))\n",
        "\n",
        "for col in ['Prior_purchases','Discount_offered']:\n",
        "    zscore = abs(stats.zscore(df[col]))\n",
        "    filtered_entries = (zscore <= 2) & filtered_entries # keep data \n",
        "    \n",
        "dfz = df[filtered_entries]\n",
        "\n",
        "print(f'Number of row after deleting outliers: {len(dfz)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTqeAwW_PrP0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05073351-8566-4250-aa78-b542c422eeab"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4260ff05-b845-42b8-984f-117928c79a64"
      },
      "source": [
        "### Gender Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5a6502c-ac30-4d37-a5db-f88e2f72359d"
      },
      "outputs": [],
      "source": [
        "map_gender = {'M' : 0, 'F':1}\n",
        "dfz['enc_gender'] = df['Gender'].map(map_gender)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c98cc48-e30d-475d-a838-a30c6d3346c8"
      },
      "source": [
        "### Product Importance Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "776353aa-2680-4263-9298-9ff869c53819"
      },
      "outputs": [],
      "source": [
        "map_Pi = {'low' : 0, 'medium':1, 'high':2}\n",
        "dfz['enc_Product_importance'] = df['Product_importance'].map(map_Pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32d72bc8-f02a-452f-aba7-f1f0537514a7"
      },
      "source": [
        "### Mode of Shipment Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33a8f78a-c596-4fc0-ac2a-84f3916dc676"
      },
      "outputs": [],
      "source": [
        "ohe_ship = pd.get_dummies(df['Mode_of_Shipment'], prefix='mode')\n",
        "dfz = dfz.join(ohe_ship)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e303a00-654e-4073-af46-f22d063aaedb"
      },
      "source": [
        "### Warehouse Block Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f393d190-d8bd-4573-ab60-093bbb098d28"
      },
      "outputs": [],
      "source": [
        "ohe_ware = pd.get_dummies(df['Warehouse_block'], prefix='Warehouse')\n",
        "df_final = dfz.join(ohe_ware)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65ac96f0-6553-47a0-ac91-ad67861cf504"
      },
      "outputs": [],
      "source": [
        "df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b073864-34d1-48fc-85fb-49ae16e24847"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler as ss\n",
        "df_final['std_Customer_care_calls'] = ss().fit_transform(df_final['Customer_care_calls'].values.reshape(len(df_final),1))\n",
        "df_final['std_Customer_rating'] = ss().fit_transform(df_final['Customer_rating'].values.reshape(len(df_final),1))\n",
        "df_final['std_Cost_of_the_Product'] = ss().fit_transform(df_final['Cost_of_the_Product'].values.reshape(len(df_final),1))\n",
        "df_final['std_Prior_purchases'] = ss().fit_transform(df_final['Prior_purchases'].values.reshape(len(df_final),1))\n",
        "df_final['std_Discount_offered'] = ss().fit_transform(df_final['Discount_offered'].values.reshape(len(df_final),1))\n",
        "df_final['std_Weight_in_gms'] = ss().fit_transform(df_final['Weight_in_gms'].values.reshape(len(df_final),1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a84c2bce-0c05-4d25-8e88-c652b13a548f"
      },
      "outputs": [],
      "source": [
        "df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8298d560-1fef-494a-aa35-c247144473ca"
      },
      "outputs": [],
      "source": [
        "df_end = df_final.drop(columns = ['Warehouse_block', 'Mode_of_Shipment', 'Customer_care_calls',\n",
        "                                  'Customer_rating', 'Cost_of_the_Product', 'Prior_purchases',\n",
        "                                  'Product_importance', 'Gender', 'Discount_offered', 'Weight_in_gms', 'enc_gender'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1ad4072-e9e4-4443-a12a-66b0477c877e"
      },
      "outputs": [],
      "source": [
        "df_end"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}